{
    "workflows": [
        {
            "name": "LoRA",
            "description": "Efficiently adapts large models by adding small trainable layers, reducing memory and compute needs without changing model weights.",
            "file": "lora/infra/provision/finetuning.config.json",
            "template": "finetuning_configs/microsoft/phi-silica-3.6",
            "version": 1,
            "templateName": "lora"
        },
        {
            "name": "Soft Prompt",
            "description": "Tunes models by learning prompt embeddings, enabling task adaptation without changing model weights.",
            "file": "soft_prompt/infra/provision/finetuning.config.json",
            "template": "finetuning_configs/microsoft/phi-silica-3.6",
            "version": 1,
            "templateName": "soft_prompt"
        }
    ],
    "modelInfo": {
        "id": "microsoft/phi-silica-3.6",
        "type": "finetuning",
        "version": 1
    }
}
