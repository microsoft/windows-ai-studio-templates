{
    "workflows": [
        {
            "name": "Convert Text Model to QNN",
            "file": "laion_clip_text_qnn.json",
            "template": "huggingface/laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
            "version": 1,
            "templateName": "laion_clip_text_qnn",
            "phases": [
                "Conversion",
                "Quantization",
                "Evaluation"
            ]
        },
        {
            "name": "Convert Vision Model to QNN",
            "file": "laion_clip_vision_qnn.json",
            "template": "huggingface/laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
            "version": 1,
            "templateName": "laion_clip_vision_qnn",
            "phases": [
                "Conversion",
                "Quantization",
                "Evaluation"
            ]
        }
    ],
    "modelInfo": {
        "displayName": "laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
        "icon": "laion",
        "modelLink": "https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
        "id": "huggingface/laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
        "runtimes": [
            "QNN"
        ],
        "architecture": "CNN",
        "status": "Ready",
        "version": 1
    }
}