{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"./model/model.onnx\"\n",
    "\n",
    "ExecutionProvider=\"QNNExecutionProvider\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ffb42-3569-4d78-b99d-355a38fdce35",
   "metadata": {},
   "source": [
    "### Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_winrt_runtime():\n",
    "    \"\"\"This function removes the msvcp140.dll from the winrt-runtime package.\n",
    "    So it does not cause issues with other libraries.\n",
    "    \"\"\"\n",
    "    from importlib import metadata\n",
    "    from pathlib import Path\n",
    "    site_packages_path = Path(str(metadata.distribution('winrt-runtime').locate_file('')))\n",
    "    dll_path = site_packages_path / 'winrt' / 'msvcp140.dll'\n",
    "    if dll_path.exists():\n",
    "        dll_path.unlink()\n",
    "            \n",
    "def _get_ep_paths() -> dict[str, str]:\n",
    "    from winui3.microsoft.windows.applicationmodel.dynamicdependency.bootstrap import (\n",
    "        InitializeOptions,\n",
    "        initialize\n",
    "    )\n",
    "    import winui3.microsoft.windows.ai.machinelearning as winml\n",
    "    eps = {}\n",
    "    with initialize(options = InitializeOptions.ON_NO_MATCH_SHOW_UI):\n",
    "        catalog = winml.ExecutionProviderCatalog.get_default()\n",
    "        providers = catalog.find_all_providers()\n",
    "        for provider in providers:\n",
    "            provider.ensure_ready_async().get()\n",
    "            eps[provider.name] = provider.library_path\n",
    "            # DO NOT call provider.try_register in python. That will register to the native env.\n",
    "    return eps\n",
    "\n",
    "def _regsiter_executino_providers_to_onnxruntime():\n",
    "    import onnxruntime as ort\n",
    "\n",
    "    paths = _get_ep_paths()\n",
    "    for item in paths.items():\n",
    "        print(f\"----register ort ep---- {item[0]} {item[1]}\")\n",
    "        ort.register_execution_provider_library(item[0], item[1])\n",
    "\n",
    "_fix_winrt_runtime()\n",
    "_regsiter_executino_providers_to_onnxruntime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d84cd-4853-4746-bce3-b281bfc23d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor\n",
    "\n",
    "processor = CLIPProcessor.from_pretrained(\"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568eb71-5812-4c74-989c-c12271d33b12",
   "metadata": {},
   "source": [
    "### Model Inference with ORT-QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bad4ec-f477-4659-8584-00735f6ed5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def add_ep_for_device(session_options, ep_name, device_type, ep_options=None):\n",
    "    ep_devices = ort.get_ep_devices()\n",
    "    for ep_device in ep_devices:\n",
    "        if ep_device.ep_name == ep_name and ep_device.device.type == device_type:\n",
    "            print(f\"Adding {ep_name} for {device_type}\")\n",
    "            session_options.add_provider_for_devices([ep_device], {} if ep_options is None else ep_options)\n",
    "\n",
    "\n",
    "session_options = ort.SessionOptions()\n",
    "\n",
    "add_ep_for_device(session_options, ExecutionProvider, ort.OrtHardwareDeviceType.NPU)\n",
    "\n",
    "vision_model = ort.InferenceSession(\n",
    "    onnx_model_path, # a model wirh QNN EPContext nodes\n",
    "    sess_options=session_options,\n",
    ")\n",
    "\n",
    "def get_image_embedding(image):\n",
    "    inputs = processor(images=image, return_tensors=\"np\")\n",
    "    output = vision_model.run(None, { \"pixel_values\": inputs[\"pixel_values\"] })\n",
    "    return torch.from_numpy(output[0])\n",
    "\n",
    "def calculate_score(emb_1, emb_2):\n",
    "    emb_1 /= torch.norm(emb_1, dim=-1, keepdim=True)\n",
    "    emb_2 /= torch.norm(emb_2, dim=-1, keepdim=True)\n",
    "    return torch.matmul(emb_1, emb_2.T) * 100.0\n",
    "\n",
    "# Get source embedding and calculate the similarity score for each target\n",
    "# We need to process one by one because to static quantization, we fixed the batch size to 1\n",
    "def ask(source, targets):\n",
    "    source_emb = get_image_embedding(source)\n",
    "    for i, target in enumerate(targets):\n",
    "        target_emb = get_image_embedding(target)\n",
    "        score = calculate_score(source_emb, target_emb)\n",
    "        print(f\"Similarity score of image {i}ï¼š{score.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477e36c-2e72-432b-ae81-602073a3754c",
   "metadata": {},
   "source": [
    "### Play with Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16868fbd-e447-4866-af7d-eb6e49975bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07076b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/train2017/000000208833.jpg\"\n",
    "image1 = Image.open(requests.get(url, stream=True).raw)\n",
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10de7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/train2017/000000125690.jpg\"\n",
    "image2 = Image.open(requests.get(url, stream=True).raw)\n",
    "image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdc2a6-4c81-4f93-8426-065ee4c2b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(image, [image1, image2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
