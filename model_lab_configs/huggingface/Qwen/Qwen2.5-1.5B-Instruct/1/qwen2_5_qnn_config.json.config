{
    "useModelBuilder": true,
    "isGPURequired": true,
    "runtimeOverwrite": {
        "pyEnvPath": "systems.qnn_system.python_environment_path",
        "ep": "CUDAExecutionProvider"
    },
    "executeRuntimeFeatures": [
        "AutoGptq"
    ],
    "evalRuntimeFeatures": [
        "Nightly"
    ],
    "addCpu": false,
    "runtime": {
        "name": "Evaluate on",
        "type": "enum",
        "displayNames": [
            "Qualcomm NPU"
        ],
        "path": "systems.qnn_system.accelerators.0.execution_providers.0",
        "values": [
            "QNNExecutionProvider"
        ],
        "fixed": false
    },
    "sections": [
        {
            "name": "Convert",
            "phase": "Conversion",
            "parameters": [],
            "toggle": {
                "name": "Convert to ONNX format",
                "type": "bool",
                "path": "passes.mb",
                "actions": [
                    [],
                    []
                ],
                "fixed": true
            }
        },
        {
            "name": "Quantize",
            "phase": "Quantization",
            "parameters": [
                {
                    "name": "Activation Type",
                    "tags": [
                        "ActivationType"
                    ],
                    "description": "Quantization data type of activation. ‘QInt8’ for signed 8-bit integer, ‘QUInt8’ for unsigned 8-bit integer etc.",
                    "descriptionLink": "https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html",
                    "type": "enum",
                    "displayType": "RadioGroup",
                    "path": "passes.sq.activation_type",
                    "values": [
                        "QInt8",
                        "QUInt8",
                        "QInt16",
                        "QUInt16"
                    ],
                    "template": {
                        "path": "passes.sq.activation_type",
                        "template": "ActivationType"
                    }
                },
                {
                    "name": "Weight Type",
                    "tags": [
                        "WeightType"
                    ],
                    "description": "Data type for quantizing weights. ‘QInt8’ for signed 8-bit integer, ‘QUInt8’ for unsigned 8-bit integer etc.",
                    "descriptionLink": "https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html",
                    "type": "enum",
                    "displayType": "RadioGroup",
                    "path": "passes.sq.weight_type",
                    "values": [
                        "QInt8",
                        "QUInt8",
                        "QInt16",
                        "QUInt16"
                    ],
                    "template": {
                        "path": "passes.sq.weight_type",
                        "template": "WeightType"
                    }
                },
                {
                    "name": "Quantization Dataset",
                    "tags": [
                        "QuantizationDataset"
                    ],
                    "type": "enum",
                    "path": "data_configs[0].load_dataset_config.data_name",
                    "values": [
                        "wikitext"
                    ],
                    "template": {
                        "path": "data_configs[0].load_dataset_config.data_name",
                        "values": [
                            "wikitext"
                        ],
                        "template": "QuantizationDataset"
                    }
                },
                {
                    "name": "Quantization Dataset Subset",
                    "type": "enum",
                    "path": "data_configs[0].load_dataset_config.subset",
                    "values": [
                        "wikitext-103-raw-v1",
                        "wikitext-103-v1",
                        "wikitext-2-raw-v1",
                        "wikitext-2-v1"
                    ]
                },
                {
                    "name": "Quantization Dataset Split",
                    "type": "enum",
                    "path": "data_configs[0].load_dataset_config.split",
                    "values": [
                        "train",
                        "validation",
                        "test"
                    ],
                    "template": {
                        "path": "data_configs[0].load_dataset_config.split",
                        "template": "QuantizationDatasetSplit"
                    }
                },
                {
                    "name": "Quantization Dataset Size",
                    "type": "int",
                    "path": "data_configs[0].pre_process_data_config.max_samples",
                    "template": {
                        "path": "data_configs[0].pre_process_data_config.max_samples",
                        "template": "QuantizationDatasetSize"
                    }
                }
            ],
            "toggle": {
                "name": "Quantize model",
                "type": "bool",
                "path": "passes.mb",
                "actions": [
                    [],
                    []
                ],
                "fixed": true
            }
        }
    ]
}