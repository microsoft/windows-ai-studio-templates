{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"./model/model.onnx\"\n",
    "\n",
    "ExecutionProvider=\"QNNExecutionProvider\"\n",
    "if ExecutionProvider == \"OpenVINOExecutionProvider\":\n",
    "    onnx_model_path = \"./model/ov_model_st_quant.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the ONNX model\n",
    "def add_ep_for_device(session_options, ep_name, device_type, ep_options=None):\n",
    "    ep_devices = ort.get_ep_devices()\n",
    "    for ep_device in ep_devices:\n",
    "        if ep_device.ep_name == ep_name and ep_device.device.type == device_type:\n",
    "            print(f\"Adding {ep_name} for {device_type}\")\n",
    "            session_options.add_provider_for_devices([ep_device], {} if ep_options is None else ep_options)\n",
    "\n",
    "\n",
    "session_options = ort.SessionOptions()\n",
    "\n",
    "add_ep_for_device(session_options, ExecutionProvider, ort.OrtHardwareDeviceType.NPU)\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    onnx_model_path, # a model wirh QNN EPContext nodes\n",
    "    sess_options=session_options,\n",
    ")\n",
    "\n",
    "def areParaphrases(sentence1, sentence2):\n",
    "    # Tokenize the input sentences\n",
    "    inputs = tokenizer(sentence1, sentence2, return_tensors='np', padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "    # Convert inputs to numpy arrays\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "    # Run inference\n",
    "    outputs = session.run(None, {\n",
    "        'input_ids': input_ids.astype(np.int64),\n",
    "        'attention_mask': attention_mask.astype(np.int64),\n",
    "        'token_type_ids': token_type_ids.astype(np.int64)\n",
    "    })\n",
    "\n",
    "    # Get the prediction\n",
    "    logits = outputs[0]\n",
    "    predicted_label = np.argmax(logits, axis=1)\n",
    "    return predicted_label == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input data\n",
    "sentence1 = \"The company Hugging Face is based in New York City.\"\n",
    "sentence2 = \"Hugging Face's headquarters are situated in NYC.\"\n",
    "sentence3 = \"New York City is big.\"\n",
    "\n",
    "# Interpret the result\n",
    "if areParaphrases(sentence1, sentence2):\n",
    "    print(\"Expected: The sentences are paraphrases.\")\n",
    "else:\n",
    "    print(\"Not expected: The sentences are not paraphrases.\")\n",
    "\n",
    "if areParaphrases(sentence1, sentence3):\n",
    "    print(\"Not expected: The sentences are paraphrases.\")\n",
    "else:\n",
    "    print(\"Expected: The sentences are not paraphrases.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
