{
    "workflows": [
        {
            "name": "Text to QNN",
            "file": "openai_clip_text_qnn.json",
            "template": "huggingface/openai/clip-vit-base-patch16",
            "version": 1,
            "templateName": "openai_clip_text_qnn",
            "modelInfo": {
                "displayName": "openai/clip-vit-base-patch16",
                "icon": "OpenAI",
                "modelLink": "https://huggingface.co/openai/clip-vit-base-patch16",
                "id": "huggingface/openai/clip-vit-base-patch16",
                "runtimes": [
                    "QNN"
                ],
                "architecture": "CNN",
                "status": "Ready",
                "version": 1
            },
            "phases": [
                "Conversion",
                "Quantization"
            ]
        },
        {
            "name": "Vision to QNN",
            "file": "openai_clip_vision_qnn.json",
            "template": "huggingface/openai/clip-vit-base-patch16",
            "version": 1,
            "templateName": "openai_clip_vision_qnn",
            "modelInfo": {
                "displayName": "openai/clip-vit-base-patch16",
                "icon": "OpenAI",
                "modelLink": "https://huggingface.co/openai/clip-vit-base-patch16",
                "id": "huggingface/openai/clip-vit-base-patch16",
                "runtimes": [
                    "QNN"
                ],
                "architecture": "CNN",
                "status": "Ready",
                "version": 1
            },
            "phases": [
                "Conversion",
                "Quantization"
            ]
        }
    ]
}