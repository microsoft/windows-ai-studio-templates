{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897ffb42-3569-4d78-b99d-355a38fdce35",
   "metadata": {},
   "source": [
    "### Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d84cd-4853-4746-bce3-b281bfc23d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor\n",
    "\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568eb71-5812-4c74-989c-c12271d33b12",
   "metadata": {},
   "source": [
    "### Model Inference with ORT-QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f0d91-eb0a-4cfe-9582-d5b1e71025bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "text_model_path = Path(\"./model/model.onnx\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bad4ec-f477-4659-8584-00735f6ed5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#qnn session\n",
    "options = ort.SessionOptions()\n",
    "# options.add_session_config_entry(\"session.disable_cpu_ep_fallback\", \"1\")\n",
    "text_model = ort.InferenceSession(text_model_path,\n",
    "    sess_options=options,\n",
    "    providers=[\"QNNExecutionProvider\"],\n",
    "    provider_options=[{\"backend_path\": \"QnnHtp.dll\"}])\n",
    "\n",
    "def _create_4d_mask(mask, input_shape, masked_value=-50.0):\n",
    "    batch_sz, seq_len = input_shape\n",
    "    expanded_mask = mask[:, None, None, :].expand(\n",
    "        batch_sz, 1, seq_len, seq_len)\n",
    "    inverted_mask = 1.0 - expanded_mask.float()\n",
    "    return inverted_mask.masked_fill(inverted_mask.bool(), masked_value)\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    inputs = processor(\n",
    "        text=text,\n",
    "        padding=\"max_length\",\n",
    "        max_length=77,#text_model.sequence_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    mask = _create_4d_mask(\n",
    "            inputs[\"attention_mask\"],\n",
    "            inputs[\"input_ids\"].shape,\n",
    "        )\n",
    "    output = text_model.run(None, {\n",
    "        \"input_ids\": inputs[\"input_ids\"].numpy().astype(np.int32),\n",
    "        \"attention_mask\": mask.numpy(),\n",
    "    })\n",
    "    return torch.from_numpy(output[0])\n",
    "\n",
    "def calculate_score(emb_1, emb_2):\n",
    "    emb_1 /= torch.norm(emb_1, dim=-1, keepdim=True)\n",
    "    emb_2 /= torch.norm(emb_2, dim=-1, keepdim=True)\n",
    "    return torch.matmul(emb_1, emb_2.T) * 100.0\n",
    "\n",
    "# Get source embedding and calculate the similarity score for each target\n",
    "# We need to process one by one because to static quantization, we fixed the batch size to 1\n",
    "def ask(source, targets):\n",
    "    source_emb = get_text_embedding(source)\n",
    "    scores = []\n",
    "    for target in targets:\n",
    "        target_emb = get_text_embedding(target)\n",
    "        score = calculate_score(source_emb, target_emb)\n",
    "        scores.append(score)\n",
    "    return torch.tensor(scores).softmax(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477e36c-2e72-432b-ae81-602073a3754c",
   "metadata": {},
   "source": [
    "### Play with Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdc2a6-4c81-4f93-8426-065ee4c2b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"a photo containing two cats\", [\"a photo of tshirt\", \"a photo of two cats\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
