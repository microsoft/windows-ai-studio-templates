{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Who is Isaac Newton?'\n",
    "ExecutionProvider=\"OpenVINOExecutionProvider\"\n",
    "model_folder = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime_genai as og\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def get_session_options(obj):\n",
    "    if type(obj) is dict:\n",
    "        for k, v in obj.items():\n",
    "            if k == \"session_options\":\n",
    "                yield v\n",
    "            else:\n",
    "                for x in get_session_options(v):\n",
    "                    yield x\n",
    "    elif type(obj) is list:\n",
    "        for v in obj:\n",
    "            for x in get_session_options(v):\n",
    "                yield x\n",
    "\n",
    "\n",
    "def remove_provider_options(model_path):\n",
    "    genai_config_path = Path(model_path) / \"genai_config.json\"\n",
    "    data = json.loads(genai_config_path.read_text())\n",
    "    for session_option in get_session_options(data):\n",
    "        if 'provider_options' in session_option:\n",
    "            session_option['provider_options'] = [{k: dict() for k in opts.keys()} for opts in session_option['provider_options']]\n",
    "\n",
    "    json.dump(data, genai_config_path.open(\"w\"), indent=4)\n",
    "\n",
    "if ExecutionProvider == \"QNNExecutionProvider\":\n",
    "    remove_provider_options(model_folder)\n",
    "\n",
    "# Load the base model and tokenizer\n",
    "model = og.Model(model_folder)\n",
    "tokenizer = og.Tokenizer(model)\n",
    "tokenizer_stream = tokenizer.create_stream()\n",
    "\n",
    "# Set the max length to something sensible by default,\n",
    "# since otherwise it will be set to the entire context length\n",
    "search_options = {}\n",
    "search_options[\"max_length\"] = 200\n",
    "\n",
    "chat_template = \"<|user|>\\n{input} <|end|>\\n<|assistant|>\"\n",
    "\n",
    "# Generate prompt (prompt template + input)\n",
    "prompt = f\"{chat_template.format(input=text)}\"\n",
    "\n",
    "# Encode the prompt using the tokenizer\n",
    "input_tokens = tokenizer.encode(prompt)\n",
    "\n",
    "# Create params and generator\n",
    "params = og.GeneratorParams(model)\n",
    "params.set_search_options(**search_options)\n",
    "generator = og.Generator(model, params)\n",
    "\n",
    "# Append input tokens to the generator\n",
    "generator.append_tokens(input_tokens)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Output: \", end=\"\", flush=True)\n",
    "\n",
    "token_times = []\n",
    "\n",
    "# Stream the output\n",
    "while not generator.is_done():\n",
    "    start_time = time.time()\n",
    "    generator.generate_next_token()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Record the time for this token generation\n",
    "    token_time = end_time - start_time\n",
    "    token_times.append(token_time)\n",
    "\n",
    "    new_token = generator.get_next_tokens()[0]\n",
    "    print(tokenizer_stream.decode(new_token), end=\"\", flush=True)\n",
    "\n",
    "print()\n",
    "\n",
    "# Calculate and display timing statistics\n",
    "if token_times:\n",
    "    total_tokens = len(token_times)\n",
    "    avg_time = sum(token_times) / total_tokens\n",
    "    \n",
    "    print(f\"Total tokens generated: {total_tokens}\")\n",
    "    print(f\"Average time per token: {avg_time:.4f} seconds\")\n",
    "    print(f\"Tokens per second: {total_tokens / sum(token_times):.2f}\")\n",
    "\n",
    "del generator\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
