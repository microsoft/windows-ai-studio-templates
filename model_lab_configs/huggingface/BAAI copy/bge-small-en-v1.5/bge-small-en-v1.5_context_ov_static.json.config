{
    "name": "Convert to Intel CPU/NPU/GPU",
    "oliveFile": "bge/bge-small-en-v1.5_ptq_qnn.json",
    "isIntel": true,
    "debugInfo": {
        "autoGenerated": true,
        "useOpenVINOOptimumConversion": "optimum_convert"
    },
    "addCpu": false,
    "runtime": {
        "autoGenerated": true,
        "name": "Evaluate on",
        "type": "enum",
        "displayNames": [
            "Intel CPU",
            "Intel GPU",
            "Intel NPU"
        ],
        "path": "systems.local_system.accelerators.0.device",
        "values": [
            "cpu",
            "gpu",
            "npu"
        ],
        "readOnly": false
    },
    "runtimeInConversion": {
        "autoGenerated": true,
        "name": "Convert/Quantize to",
        "type": "enum",
        "displayNames": [
            "Intel CPU",
            "Intel GPU",
            "Intel NPU"
        ],
        "path": "passes.optimum_convert.extra_args.device",
        "values": [
            "cpu",
            "gpu",
            "npu"
        ],
        "actions": [
            [
                {
                    "type": "update",
                    "path": "passes.ov_quantize.target_device",
                    "value": "cpu"
                },
                {
                    "type": "update",
                    "path": "passes.encapsulation.target_device",
                    "value": "cpu"
                }
            ],
            [
                {
                    "type": "update",
                    "path": "passes.ov_quantize.target_device",
                    "value": "gpu"
                },
                {
                    "type": "update",
                    "path": "passes.encapsulation.target_device",
                    "value": "gpu"
                }
            ],
            [
                {
                    "type": "update",
                    "path": "passes.ov_quantize.target_device",
                    "value": "npu"
                },
                {
                    "type": "update",
                    "path": "passes.encapsulation.target_device",
                    "value": "npu"
                }
            ]
        ]
    },
    "sections": [
        {
            "autoGenerated": true,
            "name": "Convert",
            "phase": "Conversion",
            "parameters": [],
            "toggle": {
                "autoGenerated": true,
                "name": "Convert to ONNX format",
                "type": "bool",
                "path": "passes.optimum_convert",
                "actions": [
                    [],
                    []
                ],
                "readOnly": true
            }
        },
        {
            "name": "Quantize",
            "phase": "Quantization",
            "parameters": [
                {
                    "name": "Quantization Dataset",
                    "tags": [
                        "QuantizationDataset"
                    ],
                    "type": "enum",
                    "path": "data_configs[0].load_dataset_config.data_name",
                    "values": [
                        "wikipedia"
                    ],
                    "template": {
                        "path": "data_configs[0].load_dataset_config.data_name",
                        "values": [
                            "wikipedia"
                        ],
                        "template": "QuantizationDataset"
                    }
                },
                {
                    "name": "Quantization Dataset Split",
                    "tags": [
                        "QuantizationDatasetSplit",
                        "DependsOnDataset"
                    ],
                    "type": "enum",
                    "path": "data_configs[0].load_dataset_config.split",
                    "values": [
                        "train",
                        "validation",
                        "test"
                    ],
                    "template": {
                        "path": "data_configs[0].load_dataset_config.split",
                        "template": "QuantizationDatasetSplit"
                    }
                },
                {
                    "name": "Quantization Dataset Size",
                    "type": "int",
                    "path": "data_configs[0].load_dataset_config.max_samples",
                    "template": {
                        "path": "data_configs[0].load_dataset_config.max_samples",
                        "template": "QuantizationDatasetSize"
                    }
                }
            ],
            "toggle": {
                "autoGenerated": true,
                "name": "Quantize model",
                "type": "bool",
                "path": "passes.optimum_convert",
                "actions": [
                    [],
                    []
                ],
                "readOnly": true
            }
        },
        {
            "name": "Evaluate",
            "phase": "Evaluation",
            "parameters": [],
            "toggle": {
                "autoGenerated": true,
                "name": "Evaluate model performance",
                "type": "bool",
                "path": "evaluator",
                "actions": [
                    [],
                    [
                        {
                            "type": "delete",
                            "path": "evaluator"
                        }
                    ]
                ]
            }
        }
    ]
}
