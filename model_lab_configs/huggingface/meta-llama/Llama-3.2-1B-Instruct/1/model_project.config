{
    "workflows": [
        {
            "name": "Convert to QNN",
            "file": "llama3_2_qnn_config.json",
            "template": "huggingface/meta-llama/Llama-3.2-1B-Instruct",
            "version": 1,
            "templateName": "llama3_2_qnn_config",
            "phases": [
                "Conversion",
                "Quantization"
            ],
            "useModelBuilder": true,
            "isGPURequired": true
        }
    ],
    "modelInfo": {
        "displayName": "meta-llama/Llama-3.2-1B-Instruct",
        "icon": "meta",
        "modelLink": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "id": "huggingface/meta-llama/Llama-3.2-1B-Instruct",
        "runtimes": [
            "QNN"
        ],
        "architecture": "Transformer",
        "status": "Ready",
        "version": 1
    }
}