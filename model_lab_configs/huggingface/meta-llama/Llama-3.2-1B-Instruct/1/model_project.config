{
    "workflows": [
        {
            "name": "Convert to QNN",
            "file": "llama3_2_qnn_config.json",
            "template": "huggingface/meta-llama/Llama-3.2-1B-Instruct",
            "version": 1,
            "templateName": "llama3_2_qnn_config",
            "phases": [
                "Conversion",
                "Quantization"
            ],
            "useModelBuilder": true,
            "isGPURequired": true
        }
    ],
    "modelInfo": {
        "id": "huggingface/meta-llama/Llama-3.2-1B-Instruct"
    }
}