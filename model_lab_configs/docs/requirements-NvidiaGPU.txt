--extra-index-url https://download.pytorch.org/whl/cu126
# torch==2.6.0+cu126
torch==2.6.0+cu126
filelock==3.18.0
fsspec==2024.12.0
jinja2==3.1.6
networkx==3.4.2
sympy==1.13.1
typing_extensions==4.13.2
# olive-ai==0.8.0
olive-ai==0.8.0
numpy==2.2.4
onnx==1.17.0
onnxscript==0.2.4
optuna==4.3.0
pandas==2.2.3
protobuf==3.20.3
pydantic==2.11.3
pyyaml==6.0.2
torch==2.6.0+cu126
torchmetrics==1.7.1
transformers==4.51.3
# tabulate==0.9.0
tabulate==0.9.0
# datasets==3.5.0
datasets==3.5.0
aiohttp==3.11.16
dill==0.3.8
filelock==3.18.0
fsspec==2024.12.0
huggingface-hub==0.30.2
multiprocess==0.70.16
numpy==2.2.4
packaging==24.2
pandas==2.2.3
pyarrow==19.0.1
pyyaml==6.0.2
requests==2.32.3
tqdm==4.67.1
xxhash==3.5.0
# ipykernel==6.29.5
ipykernel==6.29.5
comm==0.2.2
debugpy==1.8.14
ipython==8.35.0
jupyter_client==8.6.3
jupyter_core==5.7.2
matplotlib-inline==0.1.7
nest-asyncio==1.6.0
packaging==24.2
psutil==7.0.0
pyzmq==26.4.0
tornado==6.4.2
traitlets==5.14.3
# ipywidgets==8.1.5
ipywidgets==8.1.5
comm==0.2.2
ipython==8.35.0
jupyterlab_widgets==3.0.14
traitlets==5.14.3
widgetsnbextension==4.0.14
# onnxruntime-gpu==1.21.0
onnxruntime-gpu==1.21.0
coloredlogs==15.0.1
flatbuffers==25.2.10
numpy==2.2.4
packaging==24.2
protobuf==3.20.3
sympy==1.13.1
# onnxruntime-genai-cuda==0.7.0
onnxruntime-genai-cuda==0.7.0
numpy==2.2.4
onnxruntime-gpu==1.21.0
